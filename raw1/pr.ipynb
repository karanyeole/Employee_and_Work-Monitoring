{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import shutil  # Import shutil for file and directory operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing 100 images for isha. Press 'q' to stop.\n",
      "Image 1 captured.\n",
      "Image 2 captured.\n",
      "Image 3 captured.\n",
      "Image 4 captured.\n",
      "Image 5 captured.\n",
      "Image 6 captured.\n",
      "Image 7 captured.\n",
      "Image 8 captured.\n",
      "Image 9 captured.\n",
      "Image 10 captured.\n",
      "Image 11 captured.\n",
      "Image 12 captured.\n",
      "Image 13 captured.\n",
      "Image 14 captured.\n",
      "Image 15 captured.\n",
      "Image 16 captured.\n",
      "Image 17 captured.\n",
      "Image 18 captured.\n",
      "Image 19 captured.\n",
      "Image 20 captured.\n",
      "Image 21 captured.\n",
      "Image 22 captured.\n",
      "Image 23 captured.\n",
      "Image 24 captured.\n",
      "Image 25 captured.\n",
      "Image 26 captured.\n",
      "Image 27 captured.\n",
      "Image 28 captured.\n",
      "Image 29 captured.\n",
      "Image 30 captured.\n",
      "Image 31 captured.\n",
      "Image 32 captured.\n",
      "Image 33 captured.\n",
      "Image 34 captured.\n",
      "Image 35 captured.\n",
      "Image 36 captured.\n",
      "Image 37 captured.\n",
      "Image 38 captured.\n",
      "Image 39 captured.\n",
      "Image 40 captured.\n",
      "Image 41 captured.\n",
      "Image 42 captured.\n",
      "Image 43 captured.\n",
      "Image 44 captured.\n",
      "Image 45 captured.\n",
      "Image 46 captured.\n",
      "Image 47 captured.\n",
      "Image 48 captured.\n",
      "Image 49 captured.\n",
      "Image 50 captured.\n",
      "Image 51 captured.\n",
      "Image 52 captured.\n",
      "Image 53 captured.\n",
      "Image 54 captured.\n",
      "Image 55 captured.\n",
      "Image 56 captured.\n",
      "Image 57 captured.\n",
      "Image 58 captured.\n",
      "Image 59 captured.\n",
      "Image 60 captured.\n",
      "Image 61 captured.\n",
      "Image 62 captured.\n",
      "Image 63 captured.\n",
      "Image 64 captured.\n",
      "Image 65 captured.\n",
      "Image 66 captured.\n",
      "Image 67 captured.\n",
      "Image 68 captured.\n",
      "Image 69 captured.\n",
      "Image 70 captured.\n",
      "Image 71 captured.\n",
      "Image 72 captured.\n",
      "Image 73 captured.\n",
      "Image 74 captured.\n",
      "Image 75 captured.\n",
      "Image 76 captured.\n",
      "Image 77 captured.\n",
      "Image 78 captured.\n",
      "Image 79 captured.\n",
      "Image 80 captured.\n",
      "Image 81 captured.\n",
      "Image 82 captured.\n",
      "Image 83 captured.\n",
      "Image 84 captured.\n",
      "Image 85 captured.\n",
      "Image 86 captured.\n",
      "Image 87 captured.\n",
      "Image 88 captured.\n",
      "Image 89 captured.\n",
      "Image 90 captured.\n",
      "Image 91 captured.\n",
      "Image 92 captured.\n",
      "Image 93 captured.\n",
      "Image 94 captured.\n",
      "Image 95 captured.\n",
      "Image 96 captured.\n",
      "Image 97 captured.\n",
      "Image 98 captured.\n",
      "Image 99 captured.\n",
      "Image 100 captured.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "def capture_images(output_folder, num_images=10):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Open default camera (camera index 0)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Ask the user for a name\n",
    "    namer = input(\"Enter a name for the person: \")\n",
    "\n",
    "    print(f\"Capturing {num_images} images for {namer}. Press 'q' to stop.\")\n",
    "\n",
    "    count = 0\n",
    "    while count < num_images:\n",
    "        # Read a frame from the camera\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Save the frame in the output folder\n",
    "        img_namer = f\"{namer}_{count}.png\"\n",
    "        img_path = os.path.join(output_folder, img_namer)\n",
    "        cv2.imwrite(img_path, frame)\n",
    "\n",
    "        print(f\"Image {count + 1} captured.\")\n",
    "        count += 1\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Capture Images', frame)\n",
    "\n",
    "        # Wait for 1 second\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the camera and close the window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Set the output folder\n",
    "output_folder = r\"S:\\Datasets\\persons\"\n",
    "\n",
    "# Capture 10 images with a 1-second delay\n",
    "capture_images(output_folder, num_images=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "known_encodings = []\n",
    "known_namers = []\n",
    "known_dir = r\"S:\\Datasets\\persons\"  # Change this to the absolute path of your known persons directory\n",
    "\n",
    "# Load known persons\n",
    "for file in os.listdir(known_dir):\n",
    "    file_path = os.path.join(known_dir, file)\n",
    "    if os.path.isfile(file_path):  # Check if the path is a file, not a directory\n",
    "        img = face_recognition.load_image_file(file_path)\n",
    "        # Find face encodings only if at least one face is detected\n",
    "        face_encodings = face_recognition.face_encodings(img)\n",
    "        if face_encodings:\n",
    "            img_enc = face_encodings[0]\n",
    "            known_encodings.append(img_enc)\n",
    "            known_namers.append(file.split('.')[0])\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the timedelta class\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize a variable to keep track of the last detection time (set to a time in the past)\n",
    "last_detection_time = datetime.now() - timedelta(seconds=15)  # Assuming no detection in the last 15 seconds\n",
    "k = 10\n",
    "\n",
    "# Function to perform face recognition on a given frame\n",
    "def recognize_faces(frame):\n",
    "    global k\n",
    "    global last_detection_time  # Use the global variable\n",
    "\n",
    "    # Find face locations and encodings in the current frame\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "\n",
    "    # Get the current timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Process each face in the frame\n",
    "    person_detected = False  # Flag to check if a person is detected in the current frame\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        # Compare face encoding with known encodings\n",
    "        results = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=0.4)\n",
    "        namer = \"Unknown\"  # Default namer if no match is found\n",
    "\n",
    "        for i in range(len(results)):\n",
    "            if results[i]:\n",
    "                # Extract a more general label using split\n",
    "                namer = known_namers[i].split('_')[0]\n",
    "                # Update the last detection time when a person is detected\n",
    "                last_detection_time = datetime.now()\n",
    "                person_detected = True\n",
    "                break\n",
    "\n",
    "        # Draw rectangle and label on the frame\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, namer, (left + 2, bottom + 20), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    # Add timestamp to the corner of the video\n",
    "    cv2.putText(frame, timestamp, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Check if a person is not detected in the current frame\n",
    "    if not person_detected and datetime.now() - last_detection_time > timedelta(seconds=10):\n",
    "        print(\"Person has not been detected for the last\", k, \" seconds.\")\n",
    "        k += 10\n",
    "        # Reset the last detection time\n",
    "        last_detection_time = datetime.now()\n",
    "\n",
    "    # Reset k to 0 if a person is detected\n",
    "    if person_detected:\n",
    "        k = 10\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'face_recognition' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ajay\\OneDrive\\Desktop\\New folder\\pr.ipynb Cell 5\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ajay/OneDrive/Desktop/New%20folder/pr.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m ret, frame \u001b[39m=\u001b[39m video_capture\u001b[39m.\u001b[39mread()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ajay/OneDrive/Desktop/New%20folder/pr.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Perform face recognition on the frame\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ajay/OneDrive/Desktop/New%20folder/pr.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m recognize_faces(frame)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ajay/OneDrive/Desktop/New%20folder/pr.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Display the resulting frame\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ajay/OneDrive/Desktop/New%20folder/pr.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mVideo\u001b[39m\u001b[39m'\u001b[39m, frame)\n",
      "\u001b[1;32mc:\\Users\\Ajay\\OneDrive\\Desktop\\New folder\\pr.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ajay/OneDrive/Desktop/New%20folder/pr.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mglobal\u001b[39;00m last_detection_time  \u001b[39m# Use the global variable\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ajay/OneDrive/Desktop/New%20folder/pr.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Find face locations and encodings in the current frame\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Ajay/OneDrive/Desktop/New%20folder/pr.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m face_locations \u001b[39m=\u001b[39m face_recognition\u001b[39m.\u001b[39mface_locations(frame)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ajay/OneDrive/Desktop/New%20folder/pr.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m face_encodings \u001b[39m=\u001b[39m face_recognition\u001b[39m.\u001b[39mface_encodings(frame, face_locations)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ajay/OneDrive/Desktop/New%20folder/pr.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Get the current timestamp\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'face_recognition' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize webcam\n",
    "video_capture = cv2.VideoCapture(0)  # 0 corresponds to the default camera\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Perform face recognition on the frame\n",
    "    recognize_faces(frame)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close OpenCV windowsqq\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
